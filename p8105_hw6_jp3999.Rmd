---
title: "Homework 6"
output: github_document
---

```{r}
library(tidyverse)
library(patchwork)
library(readxl)
library(broom)
library (modelr)
library(mgcv)
set.seed(1)

```

## Problem 1 

```{r}
homicide_df = 

  read_csv("./data/homicide_data.csv")  %>%
 mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```



```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

Try across cities
```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI")) 
```



```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Problem 2
Read and check class
```{r}
baby_df = 
  read_csv("./data/birthweight.csv")
sapply(baby_df, class)

```

```{r}
baby_df =
  baby_df  %>%
mutate(
         babysex = as.factor(babysex),
         mrace = as.factor(mrace),
         frace = as.factor(frace),
         malform = as.factor(malform)
         )
```

I did not detect any missing data. 

#### Proposed Model
The variables I chose for my model are average number of cigarettes smoked per day during pregnancy (smoken), mother's race (mrace), mother's age in years (momage),family's monthly income (fincome). My model was built based on the Zhang & Yang (2019) article "Maternal Smoking and Infant Low Birth Weight: Exploring the Biological Mechanism Through the Motherâ€™s Pre-pregnancy Weight Status" as they found these to be significant predictors on baby birthweight. 

https://link.springer.com/article/10.1007/s11113-019-09554-x
```{r}
model_0 = lm(bwt ~ smoken +mrace +momage + fincome, data = baby_df)
  
```




```{r}
model_0 %>%  
    broom::tidy()%>% 
knitr::kable(digits=3)
```

#### Plot of Modeled Residuals
```{r}
baby_df %>% 
  modelr::add_residuals(model_0) %>% 
  add_predictions(model_0)%>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  labs(title = "Residuals Against Fitted Values", x = "Fitted Values", y = "Residuals")
```

The plot of my model looks okay as most values seem to be close and distributed near the x axis (0). I would be interested in further exploring the values that are extreme on the negative axis. 

```{r}
model_one = lm(bwt ~ blength + gaweeks, data = baby_df)
model_two =  lm(bwt ~ bhead*blength + bhead*babysex +  blength*babysex + blength*babysex*bhead, data = baby_df)
```

```{r}
model_one %>%  
    broom::tidy()%>% 
knitr::kable(digits=3)
```

```{r}
model_two %>%  
    broom::tidy()%>% 
knitr::kable(digits=3)
```

```{r}
cv_df = 
   crossv_mc(baby_df, 100)%>% 
  mutate(
    train = map(train, as_tibble), 
    test = map(test, as_tibble)
  )
  cv_df = 
  cv_df %>% 
  mutate(
    model_0  = map(train, ~lm(bwt ~ smoken +mrace +momage + fincome, data =.x)), 
    model_one= map(train, ~ lm(bwt ~ blength + gaweeks, data =.x)),
    model_two= map(train, ~ lm(bwt ~ bhead*blength + bhead*babysex +  blength*babysex + blength*babysex*bhead, data =.x))) %>%

   mutate(
    rmse_0 = map2_dbl(model_0, test, ~rmse(model = .x, data = .y)),
    rmse_1    = map2_dbl(model_one, test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(model_two, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

Model 2 is the best given it has the lowest rmse out of the three. Model two is the one that included head circumfrence,sex, length, and their  interactions ( bhead x blength + bhead x babysex +  blength x babysex + blength x babysex x bhead)

My proposed model (0) actually has a very high rmse and thus is by far the least optimal model. 

## Problem 3

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Drawing many bootstrap samples

```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}
```

```{r}
boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )
boot_straps

```

```{r}
bootstrap_results_r_sq = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 


bootstrap_results_r_sq %>% 
  ggplot(aes(x= adj.r.squared)) +
  geom_density() +
  labs(title = "Bootstrap R^2 ", x = "Adjusted R^2", y = "Density")
```

This plot of the adjusted r^2 looks like it is normally distributed, the mean seems to be at about .91. The 95% CI (.89, .92) were calculated in the next step. 

```{r}
 bootstrap_results_r_sq %>% 
summarise(
    ci_lower = quantile(adj.r.squared, 0.025),
    ci_upper = quantile(adj.r.squared, 0.975)) %>%
knitr::kable( )
```

Results 2 
```{r}
bootstrap_results_beta = 
  boot_straps %>% 
  mutate(
    models = map(.x = strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  unnest(results) %>%
  select (strap_number, term, estimate)%>%
 mutate(
   term = str_replace(term,"\\(Intercept\\)","Intercept")) %>%
pivot_wider(
  names_from = "term", 
  values_from = "estimate")%>% 

mutate(
    log = log(Intercept * tmin)) 


```

```{r}
 bootstrap_results_beta %>% 
 summarise(
    ci_lower = quantile(log, 0.025),
    ci_upper = quantile(log, 0.975)) %>%
knitr::kable( )
```


```{r}
bootstrap_results_beta%>% 
  
  ggplot(aes(x= log)) +
  geom_density()+
  labs(title = "Bootstrap Log ", x = "Log", y = "Density")
```

This plot of the log(B0 *B1) looks like it is normally distributed, the mean seems to be at about 2.20. The 95% CI (1.97,2.06) were calculated in the next step. 
